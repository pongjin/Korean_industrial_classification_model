# Trademark data modeling
기간 : 23.01.02 ~ 23.06.30  

인턴으로 근무하는 동안 진행했던 텍스트 데이터 모델링 업무를 정리하였습니다.  
모두 오픈소스를 기반으로 진행된 프로젝트이며, 실제 업무 자료의 내용과는 차이가 있습니다.  
크게 2가지 Task를 진행하였습니다.

## 1. 한국표준산업분류(KSIC) 자동 분류 모델
__기간__ : 23.01.19 ~  진행중  
__요약__ : 지정상품과 한국표준산업분류 1 대 N 매칭을 위한 다중 분류 모델  
  초기에는 FastText 기반 단어 임베딩 + Mecab & Okt Tokenizer로 진행하였으나, 이후 SBert 를 활용하여 진행
<img src="https://velog.velcdn.com/images/pong_jin/post/2cec603b-bcbb-4567-bc73-e75df66415aa/image.png">
#### 구조( 모델 확정 후 모듈화 예정 ~5월 )
```
├── korean_industrial_classification/
   ├── 색인어_크롤러.ipynb
   ├── 색인어_및_분류명_전처리.ipynb
   ├── 지정상품명_전처리.ipynb
   ├── 예외사전.py
   ├── models/
     ├── 서비스업_모델.ipynb
     ├── 제조업_모델.ipynb
     └── 도소매업 모델.ipynb
   └── 분류_결과물.ipynb
```
***
### 세부 과제
지정상품(50000여개)를 산업 분류 내 최소단위인 세세분류(1200여개)와 1 대 N 매칭을 시킬 수 있는 방안을 찾는 과제. 관련 논문을 참고하여 임베딩을 활용한 자동분류모델의 방식을 확인. 이를 차용하여 모델 구축.

<img src="https://velog.velcdn.com/images/pong_jin/post/5bda8429-ee57-4024-b675-daf5b7e999c1/image.png">  

<img src=" https://velog.velcdn.com/images/pong_jin/post/c4b228a4-dce7-41ec-8f07-b64bea19195a/image.png">

***
### 느낀점   
데이터와 도메인에 대한 이해가 없으면 그 뒤 모든 프로세스가 힘들어진다는것을 깨달았다...😂  
그리고 역시 실무에서는 내가 배운 이론들이 잘 적용되지 않으며 어느정도 타협이 필요하다는것..😂  
분석 외적으로는 내가 만든 모델에 대해 다른 사람들에게 쉽게 설명하는 것 또한 매우 어려운 일이라는것..😂  
아직 끝나진 않았지만, 매우 좋은 경험인것 같다.
***
# Process
### Data(예시)
* 지정상품  :  분류 대상(Target). 상품 혹은 서비스의 명칭으로 대부분 1~2어절 이하 단문. 

| 명칭 | 분류번호 |
| :---: | :----: |
| 맥주 | 10 |
| 소주 | 11 |
| ... | ... |    

* 산업분류 : 분류 결과(Output)  

| 대분류 | 중분류 | 소분류 | 세분류 | 세세분류 |
| :---: | :----: | :---: | :----: | :---: |
| A(농업) | 01(농업) | 011(작물재배) | 0111(곡물 및 작물) | 01111(곡물 재배) |
|  |  |  |  | 01112(작물 재배) |
|  |  |  | 0112(향신용 작물) | 01121(과실 작물 재배) |
|  |  |  |  | 01122(고수 재배) |
| F(제조업) | 29(전기장비 제조) | 291(조명장치 제조) | 2911(전구 및 램프 제조) | 29111(전구 제조업) |
| ... | ... |  ... | ... | ... |   

* 색인어 : 모델 학습을 위해 KSIC 해설서 내 세세분류 별 색인어를 직접 크롤링하여 만든 데이터셋(Train)
<img src="https://velog.velcdn.com/images/pong_jin/post/b0a20f45-1182-43e5-a4bd-7c55780da9fd/image.PNG" width="30%" height="30%">  

| 색인어 | 세세분류명 | 세세분류코드 |
| :---: | :----: |:----: |
| 맥주 | 알코올 음료 제조 | 27130 |
| 증류식 소주 | 알코올 음료 제조 | 27130 |
| ... | ... | ... |   

***
### Preprocess
#### 토큰화(⭐️⭐️⭐️⭐️⭐️) : 이 부분에서 제일 많은 시간과 노력을 들였다  
1. __형태소 분리__ : 교착어인 한국어의 특성 상 지정상품의 의미를 최대한 살려 토큰화를 하는 과정이 매우 쉽지 않았다. 학습 데이터 내 클로로벤젠, 목공밀링기와 같이 전문(?) 용어의 비중이 높아 일반 문서들로 학습된 Mecab이나 Okt의 경우 이를 제대로 토큰화하지 못하는 경향을 보였기 때문.  
비지도학습 tokenizer인 soynlp를 사용하기엔 마땅한 학습용 데이터를 찾지 못하였기에, 앞의 두 토큰화의 일치 여부로 필터링 후 직접 오류 사례 사전을 만들어 수정하는 작업을 진행하였다.  
2. __정제__ : 사전 학습이 되지 않은 단어들을 제거하는 작업. 해당하는 약 1000여개의 상품이 해당되며 이는 전체의 5% 이하임을 확인.

#### 임베딩(⭐️⭐️⭐️) 
1. __사전 학습 여부__ : 지정상품은 선행 분석이 거의 이루어지지 않아 학습용 데이터를 구할 수 없었다. 따라서 대안책을 찾아야 했으며, 한국표준산업분류 해설서 내 색인어가 같은 단문 형식에 지정상품과 동일하거나 유사한 단어들이 대다수라 학습용으로 적합하다고 판단하였다.  
하지만 동일한 데이터는 아니므로, 지정상품에만 있는 단어들은 잘 잡지 못할 수 있다는 판단하에 사전 학습된 임베딩값을 적용하는 방식을 활용하였다. 이를 통해 학습되지 못하는 단어의 수를 줄이며, 많은 양의 데이터로 학습된 품질 좋은 임베딩 값을 가져올 수 있었다.  
2. __유사도 계산__ : 분류명과 상품명 간 벡터 유사도를 구해 모델의 변수로 사용하였다. 이를 통해 상품과 분류간 언어적 관계성을 모델에 적용할 수 있었으며, 단일 input(임베딩) 모델보다 다중 input(임베딩, 유사도) 모델에서 성능이 더 좋아짐을 확인하였다.

***
### REFERENCE
> * 오교중, 최호진, 안현각. _"기계학습 기반 단문에서의 문장 분류 방법을 이용한 한국표준산업분류,"한국정보과학회 언어공학연구회:학술대회논문집(한글 및 한국어 정보처리)_(2020):394-398. [링크](https://koreascience.kr/article/CFKO202030060861862.pub?&lang=ko&orgId=sighlt)  
> * 임정우, 문현석, 이찬희, 우찬균, 임희석. _딥러닝 기법을 활용한 산업/직업 자동코딩 시스템.한국융합학회논문지_,(2021).12(4),23-30.
[링크](https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE10659726)  
> * 김성훈. _"사용자 정의 분류체계에 따른 딥러닝 기반의 특허문서 자동분류."_ 국내박사학위논문 한성대학교 대학원, (2022). 서울
[링크](http://www.riss.kr/search/detail/DetailView.do?p_mat_type=be54d9b8bc7cdb09&control_no=7933f6ed6ac8df7effe0bdc3ef48d419)

***
## 2. 해설서 기반 단어 유사도 도출 방법론 
__기간__ : 23.04.10 ~  23.04.26  
__요약__ : 기계학습을 통해 해설서 내 상품의 정의, 특성, 거래 실정 등을 고려한 상품 간 유사도를 구하는 방법론을 연구
<img src= "https://velog.velcdn.com/images/pong_jin/post/ae05b8e1-d7e0-43af-8072-d73feec24528/image.png">
***
### 시사점   
target 값을 평균이 아닌 해당 데이터를 활용한 분류 모델에서의 임베딩 값으로 한다면 좋은 결과가 나올것 같지만,  
중간에 엎어지는 바람에 방법론에 대한 검증을 받지 못함...😂  
attention 알고리즘을 코드로 구현해보며 학습할 수 있는 좋은 경험이었음
